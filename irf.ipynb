{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "from skimage.feature import blob_doh\n",
    "import shutil\n",
    "from csv import writer, reader\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "from numpy import asarray, save, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCES_NUMBER = 1  # Should be equal for all data used\n",
    "kSize = 5  # Size of smoothing kernel\n",
    "kSigma = 1.5  # Sigma for smoothing\n",
    "d = int((kSize-1)/2)\n",
    "src_folder = \"data/skymaps/IRF/\"+str(SOURCES_NUMBER)\n",
    "matrices = []\n",
    "blob_pos = dict()\n",
    "cont = 0\n",
    "filename_dict = dict()\n",
    "with open(\"data/xml_files/\"+str(SOURCES_NUMBER)+\"/blobs.csv\") as csv_file:\n",
    "    csv_reader = reader(csv_file, delimiter=',')\n",
    "    tmp_rows = [row for row in csv_reader]\n",
    "for filename in os.listdir(src_folder):\n",
    "    if \"IRF\" in filename:\n",
    "        filename_dict[int(filename.split(\"_\")[2][:-5])] = filename\n",
    "for order_id in sorted(filename_dict):\n",
    "    blob_pos[cont] = []\n",
    "    filename = filename_dict[order_id]\n",
    "    matrices.append(fits.open(src_folder+\"/\"+filename))\n",
    "    wcs = WCS(header=(matrices[-1])[0].header)\n",
    "    for i in range(SOURCES_NUMBER):\n",
    "        sky = SkyCoord(float(tmp_rows[cont][2*i+1]), float(tmp_rows[cont][2*i+2]), unit='deg')\n",
    "        y, x= wcs.world_to_array_index(sky)\n",
    "        blob_pos[cont].append([int(x), int(y)])\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mat in enumerate(matrices[:5]):\n",
    "    plt.matshow(mat[0].data, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining methods required to smooth the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianKernel(size, sigma):\n",
    "    kernel = np.fromfunction(lambda x, y: (1/(2*np.pi*sigma**2)) * np.e ** ((-1*((x-(size-1)/2)**2+(y-(size-1)/2)**2))/(2*sigma**2)), (size, size))\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianBlur(img, kernel):\n",
    "    gaussian = np.zeros((img.shape[0]-2*d, img.shape[1]-2*d))\n",
    "    for y in range(d, img.shape[0]-d):\n",
    "        for x in range(d, img.shape[1]-d):\n",
    "            gaussian[y-d][x-d] = np.sum(np.multiply(img[y-d:y+d+1, x-d:x+d+1], kernel))\n",
    "    return gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smoothing and saving in each image in list \"matrices_smoothed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load numpy array from npy file\n",
    "matrices_smoothed = load(\"data/skymaps/IRF/\"+str(SOURCES_NUMBER)+\"/matrices_smoothed.npy\")\n",
    "dimx = (matrices[-1][0].data).shape[0]-2*d\n",
    "dimy = (matrices[-1][0].data).shape[1]-2*d\n",
    "del matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gaussianKernel(kSize, kSigma)\n",
    "matrices_smoothed = []\n",
    "for i, mat in enumerate(matrices):\n",
    "    matrices_smoothed.append(gaussianBlur(mat[0].data, kernel))\n",
    "dimx = (matrices[-1][0].data).shape[0]-2*d\n",
    "dimy = (matrices[-1][0].data).shape[1]-2*d\n",
    "del matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"data/skymaps/IRF/\"+str(SOURCES_NUMBER)+\"/matrices_smoothed.npy\", asarray(matrices_smoothed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing smoothed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of smoothed image: \", matrices_smoothed[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, mat in enumerate(matrices_smoothed[:5]):\n",
    "    plt.matshow(mat, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram to choose threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(matrices_smoothed[0].ravel(), bins=250, range=(0.0, 1.0));  # calculating histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarizing images using previously defined threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices_bin = []\n",
    "for i, mat in enumerate(matrices_smoothed):\n",
    "    matrices_bin.append(np.zeros((dimx, dimy)))\n",
    "    matrices_bin[i][mat > thresh] = 1\n",
    "del matrices_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for mat in matrices_bin[:5]:\n",
    "    plt.matshow(mat, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining method used to erode images: convolution, padding and binary erosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(img, mask, logic):\n",
    "    # Validation check\n",
    "    try:\n",
    "        if img.shape != mask.shape:\n",
    "            raise Exception('image size don\\'t fit the kernel size')\n",
    "        if not (logic == 'AND' or logic == 'OR'):\n",
    "            raise Exception(\n",
    "                'parameter logic dosen\\'t fit. Use \\'AND\\' or \\'OR\\' instead.')\n",
    "    except:\n",
    "        raise Exception('invaild data type:', type(img), '&', type(mask))\n",
    "\n",
    "    # Conv\n",
    "    imask = np.multiply(img, mask)\n",
    "\n",
    "    # Result\n",
    "    numOnekernel = len(np.where(mask == 1)[0])\n",
    "    numOne = len(np.where(imask == 1)[0])\n",
    "    if logic == 'AND':\n",
    "        if numOne == numOnekernel:\n",
    "            return 1\n",
    "        return 0\n",
    "    if logic == 'OR':\n",
    "        if numOne == 0:\n",
    "            return 0\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(img, kernel_size, border_filled):\n",
    "    # Validation check\n",
    "    try:\n",
    "        img = np.array(img)\n",
    "        if len(img.shape) != 2:\n",
    "            raise Exception('Input shape of image doesn\\'t fit.')\n",
    "        if not (border_filled == 'CONSTANT' or border_filled == 'NEAREST'):\n",
    "            raise Exception(\n",
    "                'border_filled parameter dosen\\'t fit. Use \\'CONSTANT\\' or \\'NEAREST\\' instead.'\n",
    "            )\n",
    "    except:\n",
    "        raise Exception(\n",
    "            'Invaild input image:expected ndarray or array-like data but get',\n",
    "            type(img))\n",
    "\n",
    "    # ZeroPadding\n",
    "    x, y = img.shape\n",
    "    dx, dy = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "    imgPadded = np.zeros((x + 2 * dx, y + 2 * dy))\n",
    "    fx, fy = imgPadded.shape[0] - 1, imgPadded.shape[1] - 1\n",
    "    imgPadded[dx:fx + 1 - dx, dy:fy + 1 - dy] = img\n",
    "\n",
    "    # Nearest if needed\n",
    "    if border_filled == 'NEAREST':\n",
    "        for i in range(dy):\n",
    "            imgPadded[dx:-dx, i] = imgPadded[dx:-dx, dy]\n",
    "            imgPadded[dx:-dx, fy - i] = imgPadded[dx:-dx, fy - dy]\n",
    "        for i in range(dx):\n",
    "            imgPadded[i, dy:-dy] = imgPadded[dx, dy:-dy]\n",
    "            imgPadded[fx - i, dy:-dy] = imgPadded[fx - dx, dy:-dy]\n",
    "        imgPadded[:dx, :dy] = imgPadded[dx, dy]\n",
    "        imgPadded[:dx, fy - dy:] = imgPadded[dx, fy - dy]\n",
    "        imgPadded[fx - dx:, fy - dy:] = imgPadded[fx - dx, fy - dy]\n",
    "        imgPadded[fx - dx:, :dy] = imgPadded[fx - dx, dy]\n",
    "    return imgPadded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binErosion(img, kernel, border_filled='CONSTANT', logic='AND'):\n",
    "    # Validation check\n",
    "    try:\n",
    "        img, kernel = np.array(img), np.array(kernel)\n",
    "        if len(img.shape) != 2 or len(kernel.shape) != 2:\n",
    "            raise Exception('Input shape of image or kernel doesn\\'t fit.')\n",
    "        if not (border_filled == 'CONSTANT' or border_filled == 'NEAREST'):\n",
    "            raise Exception(\n",
    "                'border_filled parameter dosen\\'t fit. Use \\'CONSTANT\\' or \\'NEAREST\\' instead.'\n",
    "            )\n",
    "    except:\n",
    "        raise Exception('invaild image type:expect ndarray but', type(img),\n",
    "                        'or', type(kernel))\n",
    "\n",
    "    x, y = img.shape\n",
    "    dx, dy = kernel.shape\n",
    "    imgOutput = np.zeros(img.shape)\n",
    "\n",
    "    # ZeroPadding\n",
    "    imgPadded = padding(img, kernel.shape, border_filled=border_filled)\n",
    "    # Erosion Main\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            imgOutput[i, j] = conv(\n",
    "                imgPadded[i:i + dx, j:j + dy], kernel, logic=logic)\n",
    "    #Return\n",
    "    return imgOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load numpy array from npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices_dilated = []\n",
    "matrices_eroded = load(\"data/skymaps/IRF/\"+str(SOURCES_NUMBER)+\"/matrices_eroded.npy\")\n",
    "del matrices_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eroding and saving each image in list \"matrices_eroded\".\n",
    "\n",
    "Showing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices_eroded = []\n",
    "matrices_dilated = []\n",
    "for mat in matrices_bin:\n",
    "    matrices_eroded.append(binErosion(copy.deepcopy(mat), np.array([[1,1], [1, 1]])))\n",
    "    #plt.matshow(matrices_eroded[-1], cmap='gray')\n",
    "del matrices_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"data/skymaps/IRF/\"+str(SOURCES_NUMBER)+\"/matrices_eroded.npy\", asarray(matrices_eroded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with opening, but results are worst for current parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for mat in matrices_eroded:\n",
    "    #matrices_dilated.append(binErosion(copy.deepcopy(mat), np.array([[1,1], [1, 1]]), logic='OR'))\n",
    "#del matrices_eroded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting blobs using skimage.feature.blob_doh and evaluating number of blobs found.\n",
    "If the number of blobs is equal to the declared value of \"SOURCES_NUMBER\" than the skymap will be saved in another folder (to be used as dataset) and the position of the blobs will be saved in a csv file in the same folder as the skymaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blobs = dict()\n",
    "mean_error_pix = []\n",
    "mean_error_angle = []\n",
    "data_taken = 0\n",
    "matrices_to_use = matrices_dilated if len(matrices_dilated) > 0 else matrices_eroded\n",
    "for i, mat in enumerate(matrices_to_use):\n",
    "    blobs[i] = []\n",
    "    cont = 0\n",
    "    blobs_doh = blob_doh(mat, max_sigma=20, threshold=.01)\n",
    "    for blob in blobs_doh:\n",
    "        y, x, r = blob\n",
    "        if r > 1:\n",
    "            cont += 1\n",
    "            blobs[i].append((int(x), int(y)))\n",
    "    if cont == SOURCES_NUMBER:\n",
    "        data_taken += 1\n",
    "    else:\n",
    "        blobs[i] = []\n",
    "print(\"Percentage of images with correct amount of blobs: \", data_taken/len(matrices_to_use)*100, \"%\")\n",
    "print(\"Showing data:\")\n",
    "with open(\"data/dataset_irf/blobs.csv\", \"a+\", newline='') as write_obj:\n",
    "    csv_writer = writer(write_obj)\n",
    "    for key in blobs.keys():\n",
    "        blobs_key = blobs[key]\n",
    "        if len(blobs_key) == SOURCES_NUMBER:\n",
    "            to_be_saved = [key, SOURCES_NUMBER]\n",
    "            for blob in blobs_key:\n",
    "                to_be_saved.append(blob)\n",
    "                closer_blob_dist = 10000\n",
    "                sky_obs = wcs.pixel_to_world(blob[0], blob[1])\n",
    "                for i, blob_true in enumerate(blob_pos[key]):\n",
    "                    sky_true = SkyCoord(float(tmp_rows[key][2*i+1]), float(tmp_rows[key][2*i+2]), unit='deg')\n",
    "                    tmp_dist = (sky_true.separation(sky_obs)).degree\n",
    "                    if tmp_dist < closer_blob_dist:\n",
    "                        closer_blob_dist = tmp_dist\n",
    "                        closer_blob = blob_true\n",
    "                mean_error_angle.append(closer_blob_dist)\n",
    "                mean_error_pix.append(np.sqrt((closer_blob[0]-blob[0])**2 + (closer_blob[1]-blob[1])**2))\n",
    "                print(\"Error in pixel: \", mean_error_pix[-1])\n",
    "                print(\"Error angle: \", mean_error_angle[-1])\n",
    "            print(\"Coping skymap and blob \", blobs_key, \" to 'dataset_irf' folder.\")\n",
    "            origin = src_folder+\"/skymap_IRF_\"+str(key)+\".fits\"\n",
    "            dest = \"data/dataset_irf/skymap_IRF_\"+str(key)+\"_\"+str(SOURCES_NUMBER)+\".fits\"\n",
    "            #shutil.copyfile(origin, dest)\n",
    "            # Add contents of list as last row in the csv file\n",
    "            #csv_writer.writerow(to_be_saved)\n",
    "print(\"Mean error pixel: \", np.mean(mean_error_pix))\n",
    "print(\"Max error in pixel: \", np.max(mean_error_pix))\n",
    "print(\"Min error in pixel: \", np.min(mean_error_pix))\n",
    "print(\"Standard deviation error pixel: \", np.std(mean_error_pix))\n",
    "print(\"Mean error angle: \", np.mean(mean_error_angle))\n",
    "print(\"Max error in angle: \", np.max(mean_error_angle))\n",
    "print(\"Min error in angle: \", np.min(mean_error_angle))\n",
    "print(\"Standard deviation error angle: \", np.std(mean_error_angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Computer Vision Lab 1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
